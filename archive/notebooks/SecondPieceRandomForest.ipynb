{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SecondPieceRandomForest\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel('df2.xlsx')\n",
    "\n",
    "data.to_csv('df2.csv', index=False)\n"
   ],
   "metadata": {
    "id": "CT_n_lJ4tPOx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1692142265599,
     "user_tz": 240,
     "elapsed": 42406,
     "user": {
      "displayName": "zeinab vosooghi",
      "userId": "04640235590116346966"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#data = pd.read_csv('FullData.csv')\n",
    "print(data.columns)\n",
    "data2=data.copy()\n"
   ],
   "metadata": {
    "id": "ejaFCWvev4io",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1692142265600,
     "user_tz": 240,
     "elapsed": 8,
     "user": {
      "displayName": "zeinab vosooghi",
      "userId": "04640235590116346966"
     }
    },
    "outputId": "7d602462-27f3-4f3d-dca9-ebcbfb55061e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cat_cols = data.columns\n",
    "for col in cat_cols:\n",
    "    data[col] = data[col].apply(lambda x: x.lower() if isinstance(x, str) else x)\n"
   ],
   "metadata": {
    "id": "JWhk8Zdkqc71",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1692142267631,
     "user_tz": 240,
     "elapsed": 2036,
     "user": {
      "displayName": "zeinab vosooghi",
      "userId": "04640235590116346966"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "data['time'] = data.apply(lambda row: (datetime.strptime(f\"{row['TIMEHR']}:{row['TIMEMIN']} {row['AMPM']}\", \"%H:%M %p\") + pd.Timedelta(hours=12)).strftime(\"%H:%M:%S\") if row['AMPM'] == 'PM' else datetime.strptime(f\"{row['TIMEHR']}:{row['TIMEMIN']} {row['AMPM']}\", \"%I:%M %p\").strftime(\"%H:%M:%S\"), axis=1)\n",
    "\n",
    "data = data.drop(['TIMEHR', 'TIMEMIN', 'AMPM'], axis=1)\n"
   ],
   "metadata": {
    "id": "FTgMWPzYwxuB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1692142270633,
     "user_tz": 240,
     "elapsed": 3004,
     "user": {
      "displayName": "zeinab vosooghi",
      "userId": "04640235590116346966"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data['time'] = data['time'].astype(str)\n",
    "data['time'] = pd.to_datetime(data['time'], format='%H:%M:%S')\n",
    "\n",
    "data['hour'] = data['time'].dt.hour\n",
    "data['minute'] = data['time'].dt.minute\n",
    "\n",
    "data = data.drop('time', axis=1)\n"
   ],
   "metadata": {
    "id": "GRGUNwsdFEN-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1692142270803,
     "user_tz": 240,
     "elapsed": 181,
     "user": {
      "displayName": "zeinab vosooghi",
      "userId": "04640235590116346966"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "databeforeNA= data.copy()\n",
    "\n",
    "num_rows = databeforeNA.shape[0]\n",
    "print(\"# of records before cleaning\", num_rows)\n",
    "databeforeNA = databeforeNA.dropna()\n",
    "num_rows = databeforeNA.shape[0]\n",
    "print(\"# of records after NA removal\", num_rows)\n"
   ],
   "metadata": {
    "id": "n6b0n3y3vAj5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1692142270804,
     "user_tz": 240,
     "elapsed": 177,
     "user": {
      "displayName": "zeinab vosooghi",
      "userId": "04640235590116346966"
     }
    },
    "outputId": "55222ef2-5dc2-45ce-8ca1-9a6799388b55"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "datawithTime=databeforeNA.copy()\n"
   ],
   "metadata": {
    "id": "ZBWvYpfCgmP3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1692142270804,
     "user_tz": 240,
     "elapsed": 5,
     "user": {
      "displayName": "zeinab vosooghi",
      "userId": "04640235590116346966"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "unique_values0 = datawithTime['RAILROAD'].unique()\n",
    "unique_values1 = datawithTime['STATE '].unique()\n",
    "unique_values2 = datawithTime['CAUSE'].unique()\n",
    "unique_values4 = datawithTime['TYPEQ'].unique()\n",
    "unique_values5 = datawithTime['TRKCLAS'].unique()\n",
    "\n"
   ],
   "metadata": {
    "id": "QtyFHI8dg8Tg",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1692142270804,
     "user_tz": 240,
     "elapsed": 4,
     "user": {
      "displayName": "zeinab vosooghi",
      "userId": "04640235590116346966"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "datawithTime = databeforeNA.copy()\n",
    "le = LabelEncoder()\n",
    "cat_cols = ['RAILROAD','STATE ', 'CAUSE']\n",
    "\n",
    "for col in cat_cols:\n",
    "    if datawithTime[col].dtype == 'object':\n",
    "        datawithTime[col] = le.fit_transform(datawithTime[col])\n",
    "\n",
    "typeq_dict = {'1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14}\n",
    "datawithTime['TYPEQ'] = datawithTime['TYPEQ'].astype(str).map(typeq_dict)\n",
    "\n"
   ],
   "metadata": {
    "id": "3FXHuiF130z5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1692142270929,
     "user_tz": 240,
     "elapsed": 129,
     "user": {
      "displayName": "zeinab vosooghi",
      "userId": "04640235590116346966"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "target_cols = ['ACCDMG', 'CASKLD', 'CASINJ', 'EVACUATE', 'CARSDMG', 'CARSHZD']\n",
    "feature_cols = ['RAILROAD', 'YEAR','MONTH', 'DAY', 'CARS', 'STATE ', 'TEMP', 'VISIBLTY', 'WEATHER',\n",
    "                'TRNSPD', 'TONS', 'TYPEQ', 'TRKCLAS', 'TYPTRK', 'POSITON1',\n",
    "                'HEADEND1', 'LOADF1', 'EMPTYF1', 'CAUSE', 'ACCTRK',\n",
    "                'HIGHSPD', 'hour', 'minute']\n",
    "datawithTime.to_csv('datawithTime.csv', index=False)\n",
    "data_FSelection = pd.read_csv('datawithTime.csv')\n",
    "\n",
    "X = data_FSelection[feature_cols]\n",
    "\n",
    "k = 5\n",
    "\n",
    "for target_col in target_cols:\n",
    "    y = data_FSelection[target_col]\n",
    "\n",
    "    selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    selector.fit(X, y)\n",
    "\n",
    "    top_k_indices = selector.get_support(indices=True)\n",
    "\n",
    "    top_k_features = [feature_cols[i] for i in top_k_indices]\n",
    "    print('Selected Features:', top_k_features)\n",
    "\n",
    "    X_top_k = X[top_k_features]\n",
    "    linreg = LinearRegression()\n",
    "    scores = cross_val_score(linreg, X_top_k, y, cv=5)\n",
    "\n",
    "    print(f'Accuracy score for {target_col}: {scores.mean()}')\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55BiTf1xKVbF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1692037694935,
     "user_tz": 240,
     "elapsed": 11367,
     "user": {
      "displayName": "zeinab vosooghi",
      "userId": "04640235590116346966"
     }
    },
    "outputId": "49fb2f53-2eb4-4206-e6f8-7addd659b41f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "target_cols = ['ACCDMG','YEAR', 'CASKLD', 'CASINJ', 'EVACUATE', 'CARSDMG', 'CARSHZD']\n",
    "feature_cols = ['RAILROAD', 'YEAR', 'MONTH', 'DAY', 'CARS', 'STATE ', 'TEMP', 'VISIBLTY', 'WEATHER',\n",
    "                'TRNSPD', 'TONS', 'TYPEQ', 'TRKCLAS', 'TYPTRK', 'POSITON1',\n",
    "                'HEADEND1', 'LOADF1', 'EMPTYF1', 'CAUSE', 'ACCTRK',\n",
    "                'HIGHSPD', 'hour', 'minute']\n",
    "\n",
    "datawithTime.to_csv('datawithTime.csv', index=False)\n",
    "data_FSelection = pd.read_csv('datawithTime.csv')\n",
    "\n",
    "X = data_FSelection[feature_cols]\n",
    "y = data_FSelection[target_cols]\n",
    "\n",
    "k = 5\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "selector = SelectFromModel(rfc, threshold=-np.inf, max_features=k)\n",
    "selector.fit(X, y)\n",
    "\n",
    "top_k_indices = selector.get_support(indices=True)\n",
    "\n",
    "top_k_features = [feature_cols[i] for i in top_k_indices]\n",
    "print('Selected Features:', top_k_features)\n",
    "\n",
    "X_top_k = X[top_k_features]\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "scores = cross_val_score(rfc, X_top_k, y, cv=5)\n",
    "\n",
    "for i, target_col in enumerate(target_cols):\n",
    "    print(f'Accuracy score for {target_col}: {scores[i]}')\n"
   ],
   "metadata": {
    "id": "uWQ4u7CISk2D"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "data = pd.read_excel('df2.xlsx')\n",
    "\n",
    "data.to_csv('df2.csv', index=False)\n",
    "\n",
    "data2=data.copy()\n",
    "\n",
    "cat_cols = data.columns\n",
    "for col in cat_cols:\n",
    "    data[col] = data[col].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "data['time'] = data.apply(lambda row: (datetime.strptime(f\"{row['TIMEHR']}:{row['TIMEMIN']} {row['AMPM']}\", \"%H:%M %p\") + pd.Timedelta(hours=12)).strftime(\"%H:%M:%S\") if row['AMPM'] == 'PM' else datetime.strptime(f\"{row['TIMEHR']}:{row['TIMEMIN']} {row['AMPM']}\", \"%I:%M %p\").strftime(\"%H:%M:%S\"), axis=1)\n",
    "\n",
    "data = data.drop(['TIMEHR', 'TIMEMIN', 'AMPM'], axis=1)\n",
    "\n",
    "data['time'] = data['time'].astype(str)\n",
    "data['time'] = pd.to_datetime(data['time'], format='%H:%M:%S')\n",
    "\n",
    "data['hour'] = data['time'].dt.hour\n",
    "data['minute'] = data['time'].dt.minute\n",
    "\n",
    "data = data.drop('time', axis=1)\n",
    "\n",
    "databeforeNA= data.copy()\n",
    "\n",
    "num_rows = databeforeNA.shape[0]\n",
    "print(\"# of records before cleaning\", num_rows)\n",
    "databeforeNA = databeforeNA.dropna()\n",
    "num_rows = databeforeNA.shape[0]\n",
    "print(\"# of records after NA removal\", num_rows)\n",
    "\n",
    "datawithTime=databeforeNA.copy()\n",
    "print(datawithTime.head())\n",
    "\n",
    "datawithTime['RAILROAD'] = datawithTime['RAILROAD'].str.lower()\n",
    "datawithTime['STATE '] = datawithTime['STATE '].str.lower()\n",
    "datawithTime['CAUSE'] = datawithTime['CAUSE'].str.lower()\n",
    "datawithTime['TYPEQ'] = datawithTime['TYPEQ'].str.lower()\n",
    "\n",
    "unique_values0 = datawithTime['RAILROAD'].unique()\n",
    "unique_values1 = datawithTime['STATE '].unique()\n",
    "unique_values2 = datawithTime['CAUSE'].unique()\n",
    "unique_values4 = datawithTime['TYPEQ'].unique()\n",
    "unique_values5 = datawithTime['TRKCLAS'].unique()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(datawithTime['RAILROAD'])\n",
    "\n",
    "data['RAILROAD encoded'] = le.transform(data['RAILROAD'])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "cat_cols = ['RAILROAD','STATE ', 'CAUSE','TYPEQ']\n",
    "for col in cat_cols:\n",
    "    print(col)\n",
    "    if datawithTime[col].dtype == 'object':\n",
    "        datawithTime[col] = le.fit_transform(datawithTime[col])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "datawithTime = databeforeNA.copy()\n",
    "print(datawithTime['TYPEQ'].unique())\n",
    "le = LabelEncoder()\n",
    "cat_cols = ['RAILROAD','STATE ', 'CAUSE']\n",
    "\n",
    "for col in cat_cols:\n",
    "    if datawithTime[col].dtype == 'object':\n",
    "        datawithTime[col] = le.fit_transform(datawithTime[col])\n",
    "\n",
    "typeq_dict = {'1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14}\n",
    "datawithTime['TYPEQ'] = datawithTime['TYPEQ'].astype(str).map(typeq_dict)\n",
    "\n",
    "one_hot = pd.get_dummies(data['STATE '])\n",
    "train_services_encoded = pd.get_dummies(data['RAILROAD'])\n",
    "\n",
    "features = pd.concat([data.drop('STATE ', axis=1), one_hot,train_services_encoded], axis=1)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "target_cols = ['ACCDMG', 'CASKLD', 'CASINJ', 'EVACUATE', 'CARSDMG', 'CARSHZD']\n",
    "feature_cols = ['RAILROAD', 'YEAR','MONTH', 'DAY', 'CARS', 'STATE ', 'TEMP', 'VISIBLTY', 'WEATHER',\n",
    "               'TRNSPD', 'TONS', 'TYPEQ', 'TRKCLAS', 'TYPTRK', 'POSITON1',\n",
    "               'HEADEND1', 'LOADF1', 'EMPTYF1', 'CAUSE', 'ACCTRK',\n",
    "               'HIGHSPD', 'hour', 'minute']\n",
    "\n",
    "datawithTime.to_csv('datawithTime.csv', index=False)\n",
    "data_FSelection = pd.read_csv('datawithTime.csv')\n",
    "\n",
    "#import numpy as np\n",
    "#import numpy as np\n",
    "#import numpy as np\n",
    "\n",
    "data = pd.read_csv('datawithTime.csv', nrows=int(1*len(pd.read_csv('datawithTime.csv'))))\n",
    "\n",
    "target_cols = ['ACCDMG', 'CASKLD', 'CASINJ', 'EVACUATE', 'CARSDMG', 'CARSHZD']\n",
    "all_feature_cols = ['RAILROAD', 'YEAR', 'MONTH', 'DAY', 'CARS', 'STATE ', 'TEMP', 'VISIBLTY', 'WEATHER',\n",
    "                    'TRNSPD', 'TONS', 'TYPEQ', 'TRKCLAS', 'TYPTRK', 'POSITON1',\n",
    "                    'HEADEND1', 'LOADF1', 'EMPTYF1', 'CAUSE', 'ACCTRK',\n",
    "                    'HIGHSPD', 'hour', 'minute']\n",
    "\n",
    "X = data[all_feature_cols]\n",
    "y = data[target_cols]\n",
    "\n",
    "for target in target_cols:\n",
    "    y_single = y[target]\n",
    "\n",
    "    k = 23\n",
    "    selector = SelectKBest(f_classif, k=k)\n",
    "    X_new = selector.fit_transform(X, y_single)\n",
    "\n",
    "    selected_feature_indices = selector.get_support(indices=True)\n",
    "    selected_feature_cols = [all_feature_cols[i] for i in selected_feature_indices]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new, y_single, test_size=0.3, random_state=42)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    X_test_new = selector.transform(X_test)\n",
    "    y_pred = rf.predict(X_test_new)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy for\", target, \":\", accuracy)\n",
    "\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion matrix for\", target, \":\\n\", confusion)\n",
    "\n",
    "    print(\"Selected feature columns:\", selected_feature_cols)\n"
   ],
   "metadata": {
    "id": "xtNER5r_6ZjB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"ForComputeCanada.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1dBimbAjM6HqGHgqK2Py19lkQCkZVG_eO\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel('df2.xlsx')\n",
    "\n",
    "data.to_csv('df2.csv', index=False)\n",
    "\n",
    "print (data.dtypes)\n",
    "\n",
    "#data = pd.read_csv('FullData.csv')\n",
    "print(data.columns)\n",
    "data2=data.copy()\n",
    "\n",
    "cat_cols = data.columns\n",
    "for col in cat_cols:\n",
    "    data[col] = data[col].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "\n",
    "print(data2)\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "data['time'] = data.apply(lambda row: (datetime.strptime(f\"{row['TIMEHR']}:{row['TIMEMIN']} {row['AMPM']}\", \"%H:%M %p\") + pd.Timedelta(hours=12)).strftime(\"%H:%M:%S\") if row['AMPM'] == 'PM' else datetime.strptime(f\"{row['TIMEHR']}:{row['TIMEMIN']} {row['AMPM']}\", \"%I:%M %p\").strftime(\"%H:%M:%S\"), axis=1)\n",
    "\n",
    "data = data.drop(['TIMEHR', 'TIMEMIN', 'AMPM'], axis=1)\n",
    "\n",
    "print(data)\n",
    "\n",
    "print(data[['time']].head())\n",
    "print(data2[['TIMEHR','TIMEMIN','AMPM']].head())\n",
    "\n",
    "print(data.dtypes)\n",
    "\n",
    "data['time'] = data['time'].astype(str)\n",
    "data['time'] = pd.to_datetime(data['time'], format='%H:%M:%S')\n",
    "\n",
    "data['hour'] = data['time'].dt.hour\n",
    "data['minute'] = data['time'].dt.minute\n",
    "\n",
    "data = data.drop('time', axis=1)\n",
    "\n",
    "print(data)\n",
    "\n",
    "print(data.columns)\n",
    "\n",
    "databeforeNA= data.copy()\n",
    "\n",
    "num_rows = databeforeNA.shape[0]\n",
    "print(\"# of records before cleaning\", num_rows)\n",
    "databeforeNA = databeforeNA.dropna()\n",
    "num_rows = databeforeNA.shape[0]\n",
    "print(\"# of records after NA removal\", num_rows)\n",
    "\n",
    "datawithTime=databeforeNA.copy()\n",
    "print(datawithTime.head())\n",
    "\n",
    "unique_values0 = datawithTime['RAILROAD'].unique()\n",
    "unique_values1 = datawithTime['STATE '].unique()\n",
    "unique_values2 = datawithTime['CAUSE'].unique()\n",
    "unique_values4 = datawithTime['TYPEQ'].unique()\n",
    "unique_values5 = datawithTime['TRKCLAS'].unique()\n",
    "\n",
    "print(len(unique_values0))\n",
    "print(len(unique_values1))\n",
    "print(len(unique_values2))\n",
    "print(len(unique_values4))\n",
    "print(len(unique_values5))\n",
    "\n",
    "print(data.dtypes)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "datawithTime = databeforeNA.copy()\n",
    "print(datawithTime['TYPEQ'].unique())\n",
    "le = LabelEncoder()\n",
    "cat_cols = ['RAILROAD','STATE ', 'CAUSE']\n",
    "\n",
    "for col in cat_cols:\n",
    "    if datawithTime[col].dtype == 'object':\n",
    "        datawithTime[col] = le.fit_transform(datawithTime[col])\n",
    "\n",
    "typeq_dict = {'1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14}\n",
    "datawithTime['TYPEQ'] = datawithTime['TYPEQ'].astype(str).map(typeq_dict)\n",
    "\n",
    "print(datawithTime['TYPEQ'].unique())\n",
    "\n",
    "print(datawithTime.dtypes)\n",
    "\n",
    "print(datawithTime[['STATE ']].head())\n",
    "print(datawithTime[['RAILROAD']].head())\n",
    "print(datawithTime[['CAUSE']].head())\n",
    "print(datawithTime[['TYPEQ']].head())\n",
    "\n",
    "print(datawithTime.dtypes)\n",
    "\n",
    "print(datawithTime.columns)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "data = pd.read_csv('datawithTime.csv', nrows=int(1*len(pd.read_csv('datawithTime.csv'))))\n",
    "\n",
    "target_cols = ['ACCDMG', 'CASKLD', 'CASINJ', 'EVACUATE', 'CARSDMG', 'CARSHZD']\n",
    "feature_cols = ['RAILROAD', 'YEAR', 'MONTH', 'DAY', 'CARS', 'STATE ', 'TEMP', 'VISIBLTY', 'WEATHER',\n",
    "                'TRNSPD', 'TONS', 'TYPEQ', 'TRKCLAS', 'TYPTRK', 'POSITON1',\n",
    "                'HEADEND1', 'LOADF1', 'EMPTYF1', 'CAUSE', 'ACCTRK',\n",
    "                'HIGHSPD', 'hour', 'minute']\n",
    "\n",
    "X = data[feature_cols]\n",
    "y = data[target_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf_models = {}\n",
    "for target in target_cols:\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "    rf.fit(X_train, y_train[target])\n",
    "    rf_models[target] = rf\n",
    "\n",
    "y_pred = {}\n",
    "for target in target_cols:\n",
    "    y_pred[target] = rf_models[target].predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrices = {}\n",
    "for target in target_cols:\n",
    "    y_true = y_test[target]\n",
    "    y_pred = y_pred[target]\n",
    "    confusion_matrices[target] = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "for target, matrix in confusion_matrices.items():\n",
    "    print(\"Confusion matrix for\", target, \":\")\n",
    "    print(matrix)\n",
    "\n",
    "accuracy = {}\n",
    "for target in target_cols:\n",
    "    accuracy[target] = accuracy_score(y_test[target], y_pred[target])\n",
    "    print(\"Accuracy for\", target, \":\", accuracy[target])\n",
    "\n",
    "target_importance_sum = {}\n",
    "\n",
    "for target in target_cols:\n",
    "    importances = rf_models[target].feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    print(\"\\nFeature ranking for\", target)\n",
    "    target_importance_sum[target] = 0  # Initialize the summation to zero\n",
    "    for f in range(X.shape[1]):\n",
    "        feature_name = feature_cols[indices[f]]\n",
    "        importance = importances[indices[f]]\n",
    "        target_importance_sum[target] += importance  # Accumulate the importance\n",
    "        print(\"%d. feature %s (%f)\" % (f + 1, feature_name, importance))\n",
    "\n",
    "print(\"\\nSummation of importance for each target column:\")\n",
    "for target, importance_sum in target_importance_sum.items():\n",
    "    print(target, \": \", importance_sum)\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K0bUEPS2ANuu",
    "outputId": "1a72ed6c-f6c5-4c2d-8cb8-55ff0e6e17d4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "data = pd.read_excel('df2.xlsx')\n",
    "\n",
    "data.to_csv('df2.csv', index=False)\n",
    "\n",
    "data2=data.copy()\n",
    "\n",
    "cat_cols = data.columns\n",
    "for col in cat_cols:\n",
    "    data[col] = data[col].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "data['time'] = data.apply(lambda row: (datetime.strptime(f\"{row['TIMEHR']}:{row['TIMEMIN']} {row['AMPM']}\", \"%H:%M %p\") + pd.Timedelta(hours=12)).strftime(\"%H:%M:%S\") if row['AMPM'] == 'PM' else datetime.strptime(f\"{row['TIMEHR']}:{row['TIMEMIN']} {row['AMPM']}\", \"%I:%M %p\").strftime(\"%H:%M:%S\"), axis=1)\n",
    "\n",
    "data = data.drop(['TIMEHR', 'TIMEMIN', 'AMPM'], axis=1)\n",
    "\n",
    "data['time'] = data['time'].astype(str)\n",
    "data['time'] = pd.to_datetime(data['time'], format='%H:%M:%S')\n",
    "\n",
    "data['hour'] = data['time'].dt.hour\n",
    "data['minute'] = data['time'].dt.minute\n",
    "\n",
    "data = data.drop('time', axis=1)\n",
    "\n",
    "databeforeNA= data.copy()\n",
    "\n",
    "num_rows = databeforeNA.shape[0]\n",
    "print(\"# of records before cleaning\", num_rows)\n",
    "databeforeNA = databeforeNA.dropna()\n",
    "num_rows = databeforeNA.shape[0]\n",
    "print(\"# of records after NA removal\", num_rows)\n",
    "\n",
    "datawithTime=databeforeNA.copy()\n",
    "print(datawithTime.head())\n",
    "\n",
    "datawithTime['RAILROAD'] = datawithTime['RAILROAD'].str.lower()\n",
    "datawithTime['STATE '] = datawithTime['STATE '].str.lower()\n",
    "datawithTime['CAUSE'] = datawithTime['CAUSE'].str.lower()\n",
    "datawithTime['TYPEQ'] = datawithTime['TYPEQ'].str.lower()\n",
    "\n",
    "unique_values0 = datawithTime['RAILROAD'].unique()\n",
    "unique_values1 = datawithTime['STATE '].unique()\n",
    "unique_values2 = datawithTime['CAUSE'].unique()\n",
    "unique_values4 = datawithTime['TYPEQ'].unique()\n",
    "unique_values5 = datawithTime['TRKCLAS'].unique()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(datawithTime['RAILROAD'])\n",
    "\n",
    "data['RAILROAD encoded'] = le.transform(data['RAILROAD'])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "cat_cols = ['RAILROAD','STATE ', 'CAUSE','TYPEQ']\n",
    "for col in cat_cols:\n",
    "    print(col)\n",
    "    if datawithTime[col].dtype == 'object':\n",
    "        datawithTime[col] = le.fit_transform(datawithTime[col])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "datawithTime = databeforeNA.copy()\n",
    "print(datawithTime['TYPEQ'].unique())\n",
    "le = LabelEncoder()\n",
    "cat_cols = ['RAILROAD','STATE ', 'CAUSE']\n",
    "\n",
    "for col in cat_cols:\n",
    "    if datawithTime[col].dtype == 'object':\n",
    "        datawithTime[col] = le.fit_transform(datawithTime[col])\n",
    "\n",
    "typeq_dict = {'1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14}\n",
    "datawithTime['TYPEQ'] = datawithTime['TYPEQ'].astype(str).map(typeq_dict)\n",
    "\n",
    "one_hot = pd.get_dummies(data['STATE '])\n",
    "train_services_encoded = pd.get_dummies(data['RAILROAD'])\n",
    "\n",
    "features = pd.concat([data.drop('STATE ', axis=1), one_hot,train_services_encoded], axis=1)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "data = pd.read_csv('datawithTime.csv')\n",
    "\n",
    "target_cols = ['ACCDMG', 'CASKLD', 'CASINJ', 'EVACUATE', 'CARSDMG', 'CARSHZD']\n",
    "feature_cols = ['RAILROAD', 'YEAR', 'MONTH', 'DAY', 'CARS', 'STATE ', 'TEMP', 'VISIBLTY', 'WEATHER',\n",
    "                'TRNSPD', 'TONS', 'TYPEQ', 'TRKCLAS', 'TYPTRK', 'POSITON1',\n",
    "                'HEADEND1', 'LOADF1', 'EMPTYF1', 'CAUSE', 'ACCTRK',\n",
    "                'HIGHSPD', 'hour', 'minute']\n",
    "\n",
    "X = data[feature_cols]\n",
    "y = data[target_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(target_cols), random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "6aTEmL2EhF1h",
    "executionInfo": {
     "status": "error",
     "timestamp": 1692218084725,
     "user_tz": 240,
     "elapsed": 2854,
     "user": {
      "displayName": "zeinab vosooghi",
      "userId": "04640235590116346966"
     }
    },
    "outputId": "91888501-d16e-4459-8d4b-3ef885a4cf90"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}